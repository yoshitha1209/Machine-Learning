{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "myFSxjPzFE75",
        "outputId": "43d981f2-92f5-40c7-bf7b-3aa42a828e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Index(['input', 'Class'], dtype='object')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Pretrained Embeddings: 100%|██████████| 1680/1680 [10:16<00:00,  2.73it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1680' max='1680' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1680/1680 09:17, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.790000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.510700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.458600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.443400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.417700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.401900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.350000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.355000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.371700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.376000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.354200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.332600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.321200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.318100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting Fine-tuned Embeddings: 100%|██████████| 1680/1680 [00:23<00:00, 71.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved pretrained and fine-tuned embeddings to Google Drive!\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Install necessary libraries\n",
        "!pip install transformers openpyxl tqdm\n",
        "\n",
        "# Step 2: Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 3: Load the dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Use the uploaded file (modify if needed)\n",
        "dataset_path = '/content/drive/MyDrive/training new 1.xlsx'\n",
        "df = pd.read_excel(dataset_path)\n",
        "\n",
        "# Check columns\n",
        "print(df.columns)\n",
        "\n",
        "# Step 4: Prepare text and labels\n",
        "texts = df['input'].astype(str).tolist()\n",
        "labels = df['Class'].tolist()\n",
        "\n",
        "# Step 5: Load GPT-2 tokenizer and model\n",
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm  # <- ADDED tqdm\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.pad_token = tokenizer.eos_token  # Important because GPT2 has no pad token\n",
        "model_pretrained = GPT2Model.from_pretrained('gpt2')\n",
        "\n",
        "# Step 6: Tokenize texts\n",
        "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# Step 7: Extract pretrained embeddings (with PROGRESS BAR)\n",
        "pretrained_embeddings_list = []\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(len(texts)), desc=\"Extracting Pretrained Embeddings\"):\n",
        "        single_input = tokenizer(texts[i], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "        output = model_pretrained(**single_input)\n",
        "        last_hidden_state = output.last_hidden_state\n",
        "        mean_embedding = last_hidden_state.mean(dim=1)\n",
        "        pretrained_embeddings_list.append(mean_embedding.squeeze(0))\n",
        "\n",
        "pretrained_embeddings = torch.stack(pretrained_embeddings_list)\n",
        "\n",
        "# Step 8: Prepare Fine-Tuning dataset\n",
        "class GPT2Dataset(Dataset):\n",
        "    def __init__(self, texts, tokenizer):\n",
        "        self.input_ids = []\n",
        "        for txt in texts:\n",
        "            encodings = tokenizer(txt, truncation=True, max_length=512, padding=\"max_length\")\n",
        "            self.input_ids.append(torch.tensor(encodings['input_ids']))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {'input_ids': self.input_ids[idx], 'labels': self.input_ids[idx]}\n",
        "\n",
        "train_dataset = GPT2Dataset(texts, tokenizer)\n",
        "\n",
        "# Step 9: Fine-tune GPT-2 (Better logging)\n",
        "model_finetuned = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "model_finetuned.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/gpt2_finetuned_output\",\n",
        "    per_device_train_batch_size=2,\n",
        "    num_train_epochs=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    prediction_loss_only=True,\n",
        "    logging_steps=100,  # <- log more frequently\n",
        "    report_to=\"none\",   # <- clean output\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model_finetuned,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Step 10: Extract embeddings after fine-tuning (with PROGRESS BAR)\n",
        "# Step 10: Extract embeddings after fine-tuning (with PROGRESS BAR)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_finetuned_model = model_finetuned.transformer.to(device)  # Move model to GPU\n",
        "\n",
        "finetuned_embeddings_list = []\n",
        "with torch.no_grad():\n",
        "    for i in tqdm(range(len(texts)), desc=\"Extracting Fine-tuned Embeddings\"):\n",
        "        single_input = tokenizer(texts[i], padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "        output = model_finetuned_model(**single_input)\n",
        "        last_hidden_state = output.last_hidden_state\n",
        "        mean_embedding = last_hidden_state.mean(dim=1)\n",
        "        finetuned_embeddings_list.append(mean_embedding.squeeze(0))\n",
        "\n",
        "finetuned_embeddings = torch.stack(finetuned_embeddings_list)\n",
        "\n",
        "\n",
        "# Step 11: Save embeddings + class to Excel\n",
        "import numpy as np\n",
        "\n",
        "pretrained_df = pd.DataFrame(pretrained_embeddings.cpu().numpy())  # <-- added .cpu()\n",
        "finetuned_df = pd.DataFrame(finetuned_embeddings.cpu().numpy())    # <-- added .cpu()\n",
        "\n",
        "pretrained_df['Class'] = labels\n",
        "finetuned_df['Class'] = labels\n",
        "\n",
        "pretrained_path = '/content/drive/MyDrive/pretrained_embeddings.xlsx'\n",
        "finetuned_path = '/content/drive/MyDrive/finetuned_embeddings.xlsx'\n",
        "\n",
        "pretrained_df.to_excel(pretrained_path, index=False)\n",
        "finetuned_df.to_excel(finetuned_path, index=False)\n",
        "\n",
        "print(\" Saved pretrained and fine-tuned embeddings to Google Drive!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
